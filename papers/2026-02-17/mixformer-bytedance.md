# MixFormer: Co-Scaling Up Dense and Sequence in Industrial Recommenders

## 基本情報
- **arXiv**: [2602.14110](https://arxiv.org/abs/2602.14110)
- **カテゴリ**: cs.IR
- **投稿日**: 2026-02-16
- **著者**: Xu Huang, Hao Zhang, Zhifang Fan, et al. (ByteDance)

## 🏭 産業実装
- **企業**: ByteDance（抖音/Douyin, Douyin Lite）
- **規模**: 大規模本番A/Bテスト実施
- **効果**: ユーザーエンゲージメント改善（アクティブ日数、アプリ使用時間）

## 概要
産業推薦システムにおけるTransformerベースのスケーラブルな統合アーキテクチャ。既存手法では系列モデリングと特徴交互作用が別モジュールとして独立にパラメタライズされており、co-scalingの課題があった。

## 技術的特徴
1. **統合パラメトリゼーション**: 系列行動と特徴交互作用を単一バックボーンで同時モデリング
2. **Co-Scaling**: Dense容量と系列長を限られた計算予算内で効率的にスケール
3. **ユーザー・アイテム分離戦略**: 推論レイテンシと冗長計算を大幅削減

## 主要結果
- 大規模産業データセットで精度・効率ともに優位性を実証
- Douyin、Douyin Liteの2つの本番推薦システムでオンラインA/Bテスト
- アクティブ日数、アプリ内使用時間の一貫した改善

## 注目ポイント
🎯 **ByteDanceの本番システム（抖音）で実際にデプロイ済み**のスケーラブル推薦モデル
