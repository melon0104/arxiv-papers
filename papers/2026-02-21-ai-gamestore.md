# AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games

- **arXiv ID**: 2602.17594
- **カテゴリ**: cs.AI
- **投稿日**: 2026-02-19
- **URL**: https://arxiv.org/abs/2602.17594

## 著者
Lance Ying, Ryan Truong, Prafull Sharma, Kaiya Ivy Zhao, Nathan Cloos, Kelsey R. Allen, **Thomas L. Griffiths**, Katherine M. Collins, José Hernández-Orallo, **Phillip Isola**, Samuel J. Gershman, **Joshua B. Tenenbaum**

## 選定理由
✅ **有名研究機関**: MIT (Tenenbaum, Isola)、Princeton (Griffiths)、Stanford
✅ **AGI評価の新パラダイム**: Human gamesを用いたオープンエンド評価

## 概要
「人間が作った人間のためのゲーム」の空間全体を用いてAIの汎用知能を評価するフレームワーク。LLMと人間のループで新しい代表的ゲームを自動生成。

## 主要な貢献
1. **AI GameStore Platform**: Apple App StoreやSteamからゲームを自動収集・適応
2. **100ゲームのPoC**: 7つのfrontier VLMを短期プレイで評価
3. **Human Games as AGI Benchmark**: 静的ベンチマークの飽和問題を解決

## 実験結果
- 最良モデルでも**大半のゲームで人間平均スコアの10%未満**
- World-model learning、Memory、Planningが特に困難

## 技術的詳細
- Containerized game variants
- Standardized evaluation protocols
- Scalable & open-ended

## 関連研究
- General game playing
- AGI evaluation
- Vision-language models
