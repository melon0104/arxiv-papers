# KLong: Training LLM Agent for Extremely Long-horizon Tasks

- **arXiv ID**: 2602.17547
- **カテゴリ**: cs.AI, cs.CL
- **投稿日**: 2026-02-19
- **URL**: https://arxiv.org/abs/2602.17547

## 著者
Yue Liu, Zhiyuan Hu, Flood Sung, Jiaheng Zhang, Bryan Hooi

## 選定理由
✅ **有名研究機関**: Claude 4.5 Sonnetからの蒸留、Kimi K2との比較

## 概要
極めて長いホライズンのタスクを解くオープンソースLLMエージェントKLongを提案。Trajectory-splitting SFTとProgressive RLの組み合わせで学習。

## 主要な貢献
1. **Research-Factory**: 論文を収集し評価ルーブリックを構築する自動パイプライン
2. **Trajectory-splitting SFT**: 早期コンテキストを保持しつつ後半を段階的に切り詰め、サブ軌跡間のオーバーラップを維持
3. **Progressive RL**: タイムアウトを段階的に延長する多段階スケジューリング

## 実験結果
- **PaperBench**: KLong (106B)がKimi K2 Thinking (1T)を**11.28%上回る**
- **SWE-bench Verified**: 汎化性能を実証
- **MLE-bench**: コーディングベンチマークでも有効性を確認

## 技術的詳細
- Claude 4.5 Sonnet (Thinking)から数千の長ホライズン軌跡を蒸留
- Long-horizon task-solving capabilityをスケーラブルに向上

## 関連研究
- LLM agents
- Reinforcement Learning for LLMs
- Long-context modeling
