# Towards a Science of AI Agent Reliability

**arXiv**: [2602.16666](https://arxiv.org/abs/2602.16666)  
**カテゴリ**: cs.AI, cs.CY, cs.LG  
**投稿日**: 2026-02-18

## 著者
- Stephan Rabanser
- Sayash Kapoor
- Peter Kirgis
- Kangheng Liu
- Saiteja Utpala
- **Arvind Narayanan**（Princeton、AI Snake Oil著者）

## 概要

標準ベンチマークでの精度向上にもかかわらず、実運用でAIエージェントが失敗し続ける問題を体系的に分析。**単一の成功指標ではエージェントの信頼性を評価できない**ことを指摘。

### 4つの信頼性次元と12の具体的指標
1. **Consistency（一貫性）**: 実行間での動作の安定性
2. **Robustness（堅牢性）**: 摂動への耐性
3. **Predictability（予測可能性）**: 失敗パターンの予測可能性
4. **Safety（安全性）**: エラー重大度の有界性

### 実験結果
- **14のエージェントモデル**を2つのベンチマークで評価
- **能力向上は信頼性向上をほとんどもたらさない**
- 従来評価の限界を暴露

## なぜ重要か
- AI安全性の第一人者Arvind Narayananの研究
- エージェント評価の根本的問題を指摘
- 実運用に向けた新評価フレームワーク
