# References Improve LLM Alignment in Non-Verifiable Domains

- **arXiv ID**: 2602.16802
- **カテゴリ**: cs.CL, cs.AI, cs.LG
- **投稿日**: 2026-02-18
- **リンク**: https://arxiv.org/abs/2602.16802
- **採択**: ICLR 2026 Camera Ready

## 概要

検証可能な報酬を用いた強化学習（RLVR）は推論タスクで有効性を示しているが、LLMアラインメントのような真のグラウンドトゥルース検証器がない非検証可能ドメインには直接適用できない。本研究では、参照ガイド型LLM評価器がこのギャップを埋め、ソフトな「検証器」として機能できるかを調査。

参照出力を用いることでLLMベースの評価器の精度が大幅に向上することを実証。特に、能力の低いLLMジャッジもフロンティアモデルからの参照を用いることで改善し、強力なLLMジャッジも高品質（人間が書いた）参照により強化される。この改善されたジャッジを用いた参照ガイド型自己改善は、SFT蒸留や参照フリー自己改善を上回り、ArmoRMに匹敵する性能を達成。

## 注目ポイント

- **ICLR 2026採択**: トップ会議
- **非検証可能ドメインへのRL拡張**: アラインメントの新パラダイム
- **実証的改善**: Llama-3-8B-InstructでAlpacaEval 73.1%、Arena-Hard 58.7%達成
