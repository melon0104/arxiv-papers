# MALLVi: Multi Agent Large Language and Vision Framework for Integrated Generalized Robotics Manipulation

- **arXiv ID**: 2602.16898
- **カテゴリ**: cs.RO, cs.AI, cs.CV, cs.LG
- **投稿日**: 2026-02-18
- **リンク**: https://arxiv.org/abs/2602.16898
- **コード**: https://github.com/iman1234ahmadi/MALLVI

## 概要

大規模言語モデル（LLM）を用いたロボットマニピュレーションのタスク計画は新興分野。従来のアプローチは専門モデル、ファインチューニング、プロンプトチューニングに依存し、しばしばロバストな環境フィードバックなしにオープンループで動作するため、動的環境で脆弱。

MALLViは、クローズドループフィードバック駆動型ロボットマニピュレーションを可能にするMulti Agent Large Language and Visionフレームワーク。自然言語指示と環境画像を入力として、ロボットマニピュレータ用の実行可能なアトミックアクションを生成。アクション実行後、Vision Language Model (VLM) が環境フィードバックを評価し、プロセスを繰り返すか次のステップに進むかを決定。

Decomposer、Localizer、Thinker、Reflectorなどの専門エージェントを協調させ、知覚、位置特定、推論、高レベル計画を管理。Reflectorはターゲットを絞ったエラー検出と回復をサポートし、完全な再計画を回避。シミュレーションと実世界での実験で、ゼロショットマニピュレーションタスクでの汎化と成功率向上を実証。

## 注目ポイント

- **クローズドループ制御**: 環境フィードバックを活用
- **マルチエージェント協調**: 専門エージェントの分業
- **ゼロショット汎化**: 新規タスクへの適応
- **コード公開**: GitHub
