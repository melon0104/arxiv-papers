---
layout: paper
title: "Small LLMs for Medical NLP: Italian Medical Tasks"
date: 2026-02-19
arxiv_id: "2602.17475"
categories: [cs.CL]
conference: "LREC 2026"
---

# Small LLMs for Medical NLP

**arXiv**: [2602.17475](https://arxiv.org/abs/2602.17475)  
**採択**: LREC 2026

## 概要

「小規模」LLM（約10億パラメータ）が医療NLPタスクで競争力のある精度を達成できるか検証。Llama-3、Gemma-3、Qwen3の3ファミリーを20の臨床NLPタスクで評価。

## 主要な貢献

1. **体系的比較**: Few-shot、制約デコーディング、ファインチューニング、継続事前学習を網羅
2. **小規模モデルの有効性**: Qwen3-1.7BがQwen3-32Bを**+9.2ポイント**上回る
3. **イタリア語医療データセット**: 病院救急部門126M語 + 各種ソース175M語を公開

## タスク範囲

- 固有表現認識（NER）
- 関係抽出
- 症例報告フォーム記入
- 質問応答
- 議論マイニング

## 実験結果

- ファインチューニングが最も効果的
- Few-shot + 制約デコーディングは低リソース環境で有効な代替
- 継続事前学習は言語適応に寄与

## 意義

医療現場での計算リソース制約を考慮した実用的アプローチ。イタリア語医療NLPリソースの充実。
