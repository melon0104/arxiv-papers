---
layout: paper
title: "Human-level 3D shape perception emerges from multi-view learning"
date: 2026-02-19
arxiv_id: "2602.17650"
categories: [cs.CV]
---

# Human-level 3D Shape Perception from Multi-view Learning

**arXiv**: [2602.17650](https://arxiv.org/abs/2602.17650)

## 概要

2D視覚入力から3D構造を推論する人間の能力をモデル化。自然なシーン内の画像セットから空間情報を予測する視覚-空間目的関数で訓練した新クラスのニューラルネットワークを開発。

## 主要な貢献

1. **Multi-viewモデル**: カメラ位置、視覚深度などの空間情報を予測
2. **オブジェクト非依存**: 物体関連の帰納バイアスに依存しない
3. **人間レベル精度**: タスク固有の訓練やファインチューニングなしでゼロショット達成

## 技術詳細

- 視覚-空間信号は人間が利用可能な感覚キューに類似
- 確立された3D知覚タスクでゼロショット評価
- モデル応答の独立した読み出しが人間行動の細粒度測定を予測

## 実験結果

- **人間の精度に初めて一致**
- エラーパターンと反応時間を予測
- モデルダイナミクスと人間知覚の自然な対応

## 意義

自然な視覚-空間データからの単純でスケーラブルな学習目的が人間レベル3D知覚を生み出せることを示す。コード・人間行動データ・実験刺激を公開。
