---
layout: paper
title: "MARS: Margin-Aware Reward-Modeling with Self-Refinement"
date: 2026-02-19
arxiv_id: "2602.17658"
categories: [cs.LG, cs.AI]
---

# MARS: Margin-Aware Reward-Modeling

**arXiv**: [2602.17658](https://arxiv.org/abs/2602.17658)

## 概要

報酬モデリングはRLHF/RLAIFの中核コンポーネント。人間ラベル選好データに依存するが高コストで限定的。MARSは曖昧・失敗モードを明示的にターゲットとした適応的データ拡張戦略を提案。

## 主要な貢献

1. **マージン認識拡張**: 報酬モデルが最も不確実な低マージン（曖昧）選好ペアに集中
2. **反復的精製**: ハードサンプル拡張による訓練分布の改善
3. **理論的保証**: 損失関数の平均曲率増加と条件付け改善を証明

## 技術詳細

- 既存の拡張手法は表現/意味レベルで動作し、報酬モデルの推定難易度を無視
- MARSは自己精製メカニズムで適応的にサンプリング
- 均一拡張を超える一貫した改善

## 実験結果

- ロバストな報酬モデリングで均一拡張を上回る
- PPO/TRPOなどのポリシー最適化に直接適用可能

## 意義

RLHF選好データの効率的活用。報酬モデルの信頼性向上に貢献。
