---
layout: paper
title: "IRPAPERS: Visual Document Benchmark for Scientific Retrieval and QA"
arxiv_id: "2602.17687"
date: 2026-02-24
categories: [cs.IR, cs.AI, cs.CL, cs.LG]
---

# IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering

## 基本情報
- **arXiv**: [2602.17687](https://arxiv.org/abs/2602.17687)
- **カテゴリ**: cs.IR, cs.AI, cs.CL, cs.LG
- **投稿日**: 2026-02-05
- **注目ポイント**: 📦 **データセット・コード公開**

## 概要
科学論文の画像ベース検索とテキストベース検索を比較するベンチマーク「IRPAPERS」を提案。3,230ページ（166論文）と180問のニードル・イン・ヘイスタック質問を含む。

## 主要な貢献
1. **マルチモーダルベンチマーク**: 各ページに画像とOCRテキストの両方を提供
2. **モダリティ比較**: 画像検索とテキスト検索の相補的な失敗パターンを発見
3. **ハイブリッド検索**: マルチモーダルハイブリッド検索が単一モダリティを上回る

## 実験結果
### テキスト検索（Arctic 2.0 + BM25 + ハイブリッド）
- Recall@1: 46%, Recall@5: 78%, Recall@20: 91%

### 画像検索
- Recall@1: 43%, Recall@5: 78%, Recall@20: 93%

### マルチモーダルハイブリッド
- Recall@1: 49%, Recall@5: 81%, Recall@20: 95%

### Cohere Embed v4（最高性能）
- Recall@1: 58%, Recall@5: 87%, Recall@20: 97%

## QA評価
- テキストベースRAG: 0.82（正解との一致度）
- 画像ベースRAG: 0.71

## 関連キーワード
Visual Document Retrieval, Multimodal RAG, Scientific QA, Benchmark
