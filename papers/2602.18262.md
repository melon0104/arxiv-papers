---
layout: paper
title: "ELIA: Explainable Language Interpretability Analysis"
arxiv_id: "2602.18262"
date: 2026-02-24
categories: [cs.CL, cs.AI, cs.LG]
---

# Simplifying Outcomes of Language Model Component Analyses with ELIA

## 基本情報
- **arXiv**: [2602.18262](https://arxiv.org/abs/2602.18262)
- **カテゴリ**: cs.CL, cs.AI, cs.LG
- **投稿日**: 2026-02-20
- **注目ポイント**: 🏆 **EACL 2026 System Demo** | 📦 **GitHub公開**
- **コード**: https://github.com/aaron0eidt/ELIA

## 概要
LLMの内部動作分析を一般ユーザーにも理解可能にするインタラクティブWebアプリ「ELIA」を提案。Vision-Language Modelを用いて複雑な可視化に自然言語説明を自動生成。

## 主要な貢献
1. **3つの解釈手法を統合**: Attribution Analysis、Function Vector Analysis、Circuit Tracing
2. **AI生成説明**: VLMを用いた自然言語説明（NLE）の自動生成
3. **ユーザー中心設計**: インタラクティブで探索可能なインターフェース

## 実験結果（混合手法ユーザースタディ）
- インタラクティブUIへの明確な選好
- AI説明が非専門家の知識ギャップを橋渡し
- **経験レベルと理解スコアに有意な相関なし**（障壁低減を示唆）

## 意義
複雑なモデル分析をAIシステムが簡略化できることを実証。インタラクティビティ、特異性、物語的ガイダンスを優先したユーザー中心設計が鍵。

## 関連キーワード
Mechanistic Interpretability, LLM Explanation, Interactive Visualization, Accessibility
