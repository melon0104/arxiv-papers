---
layout: paper
arxiv_id: "2602.20122"
title: "NanoKnow: How to Know What Your Language Model Knows"
authors: "Lingwei Gu, Nour Jedidi, Jimmy Lin"
categories: "cs.CL cs.AI cs.IR cs.LG"
published: "2026-02-23"
venue: null
github: "https://github.com/castorini/NanoKnow"
abstract: |
  How do large language models (LLMs) know what they know? Answering this question has been difficult because pre-training data is often a "black box" -- unknown or inaccessible. The recent release of nanochat -- a family of small LLMs with fully open pre-training data -- addresses this as it provides a transparent view into where a model's parametric knowledge comes from.
---

# NanoKnow: How to Know What Your Language Model Knows

## 概要

LLMが「何を知っているか」を理解するための**ベンチマークデータセット**。完全公開の事前学習データを持つnanochatファミリーを活用。

## 主な貢献

- **NanoKnow**: Natural QuestionsとSQuADの質問を、nanochatの事前学習コーパスに回答が存在するかで分割したベンチマーク
- LLMの知識源を適切に分離可能に
- **Jimmy Lin (Waterloo)** グループからの貢献

## 主な発見

1. **閉本精度は事前学習データの回答頻度に強く影響される**
2. 外部証拠の提供でこの頻度依存性を軽減可能
3. 外部証拠があっても、事前学習で見た回答の方が精度が高い（**パラメトリック知識と外部知識は補完的**）
4. 非関連情報は有害で、位置と数に応じて精度が低下

## 技術詳細

### データセット構築
- nanochat（小型LLMファミリー、完全オープン事前学習データ）を使用
- Natural QuestionsとSQuADから質問を分割

### 実験設計
- 8つのnanochatチェックポイントで検証
- 知識の起源を適切に分離

## 選定理由

**GitHub公開**、Jimmy Lin（Waterloo、IR/NLP著名研究者）、LLMの知識理解に関する基礎研究。RAGシステム設計への示唆。
