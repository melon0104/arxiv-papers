---
layout: paper
arxiv_id: "2602.20160"
title: "tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction"
authors: "Chen Wang, Hao Tan, Wang Yifan, Zhiqin Chen, Yuheng Liu, Kalyan Sunkavalli, Sai Bi, Lingjie Liu, Yiwei Hu"
categories: "cs.CV"
published: "2026-02-23"
venue: "CVPR 2026"
github: null
abstract: |
  We propose tttLRM, a novel large 3D reconstruction model that leverages a Test-Time Training (TTT) layer to enable long-context, autoregressive 3D reconstruction with linear computational complexity, further scaling the model's capability.
---

# tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction

## 概要

**Test-Time Training (TTT) レイヤー**を活用した大規模3D再構築モデル。線形計算複雑性で長コンテキスト・自己回帰的3D再構築を実現。

## 主な貢献

- **tttLRM**: TTTレイヤーによる3D再構築モデル
- 複数画像観測をTTTレイヤーのfast weightsに効率的圧縮
- **CVPR 2026採択**

## 技術詳細

### コアモジュール: Mobile Conditioning Projector (MCP)
1. 画像観測をTTTレイヤーのfast weightsに圧縮
2. 潜在空間で暗黙的3D表現を形成
3. Gaussian Splats (GS)等の明示的フォーマットにデコード可能

### 主要な特徴
- **線形計算複雑性**: モデル能力をさらにスケール
- **オンライン学習変種**: ストリーミング観測からの漸進的3D再構築・精緻化
- **Novel View Synthesisからの転移**: 明示的3Dモデリングへ効果的に転移

### 実験結果
- feedforward 3D Gaussian再構築でSOTA
- オブジェクトとシーン両方で優れた性能
- 改善された再構築品質と高速収束

## 選定理由

**CVPR 2026採択**。Test-Time Trainingという新しいパラダイムの3D再構築への適用。Adobe研究チーム関連。
