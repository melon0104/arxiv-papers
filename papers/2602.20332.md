---
layout: paper
title: "QueryBandits: Adaptive Hallucination Mitigation"
arxiv_id: "2602.20332"
date: 2026-02-26
categories: [cs.CL, cs.AI, cs.LG]
significance: "クローズドソースLLMのハルシネーション対策"
---

# QueryBandits for Hallucination Mitigation

## 基本情報
- **arXiv**: [2602.20332](https://arxiv.org/abs/2602.20332)
- **カテゴリ**: cs.CL, cs.AI, cs.LG

## 概要
クローズドソースLLMのハルシネーション緩和に焦点。モデル非依存のcontextual banditフレームワーク「QueryBandits」を提案し、最適なクエリ書き換え戦略をオンライン学習で適応的に選択。

## 主要な貢献
- **Thompson Sampling bandit**: 16 QAシナリオでNo-Rewriteベースラインに対し87.5%の勝率
- ゼロショット静的ポリシー（Paraphrase: 42.6%、Expand: 60.3%）を大幅に上回る
- 全contextual banditがvanilla banditを上回り、特徴分散が高いほどアーム選択分散も増加
- **重要発見**: 単一の書き換えポリシーが全クエリに最適ではない

## 技術的詳細
- Contextual bandit framework: セマンティック特徴に基づくオンラインポリシー学習
- 経験的に検証・キャリブレーションされた報酬関数
- Forward-passのみでモデル行動を変更（再学習・勾配適応不要）

## 注目ポイント
- クローズドソースLLM（企業デプロイの大半）への適用可能
- 固定書き換えポリシーはハルシネーションを悪化させうることを発見
- オンライン学習で継続的改善
