---
layout: paper
title: "Personal Information Parroting in Language Models"
arxiv_id: "2602.20580"
date: 2026-02-26
categories: [cs.CL, cs.AI, cs.CR, cs.LG]
significance: "EACL 2026 Findings採択"
---

# Personal Information Parroting in Language Models

## 基本情報
- **arXiv**: [2602.20580](https://arxiv.org/abs/2602.20580)
- **カテゴリ**: cs.CL, cs.AI, cs.CR, cs.LG
- **採択**: EACL 2026 Findings

## 概要
LLMがトレーニングデータから個人情報（メールアドレス、電話番号、IPアドレス）をどの程度記憶・再生するかを調査。R&R検出器スイートを開発し、既存の正規表現ベース検出器を上回る性能を達成。

## 主要な貢献
- Regexes and Rules (R&R) detector suite: メールアドレス、電話番号、IPアドレスの高精度検出
- 手動キュレーションした483インスタンスで13.6%が Pythia-6.9bで完全に再生（parrot）されることを確認
- Pythiaモデルスイート（160M-6.9B、70k-143kステップ）で分析
- モデルサイズと事前学習量の両方が記憶と正相関

## 技術的詳細
- Verbatim parroting: 元文書のPI前トークンでプロンプトし、greedy decodingで完全一致生成
- モデルスケール効果: 最小160Mでも2.7%が完全再生
- トレーニングステップ効果: 学習が進むほど記憶増加

## 推奨事項
事前学習データセットの積極的なフィルタリングと匿名化を強く推奨

## 注目ポイント
- **EACL 2026 Findings採択**
- LLMのプライバシーリスクの定量的評価
- データセット構築時の重要な知見
