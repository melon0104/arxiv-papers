---
layout: paper
title: "The Art of Efficient Reasoning: Data, Reward, and Optimization"
arxiv_id: "2602.20945"
date: 2026-02-26
categories: [cs.CL, cs.AI]
significance: "0.2M GPU時間の大規模研究、Qwen3シリーズ検証"
---

# The Art of Efficient Reasoning

## 基本情報
- **arXiv**: [2602.20945](https://arxiv.org/abs/2602.20945)
- **カテゴリ**: cs.CL, cs.AI

## 概要
LLMのChain-of-Thought（CoT）推論は強力だが計算オーバーヘッドが大きい。効率的推論の仕組みを体系的に調査し、約0.2M GPU時間の実験から実践的ガイドラインを導出。

## 主要な貢献
- **二段階学習パラダイム**の発見: 長さ適応フェーズ → 推論精緻化フェーズ
- **評価指標の提案**: 正解/不正解条件付き長さ分布、2k-32kトークン予算での性能
- **重要発見**: 比較的容易なプロンプトで訓練することで、正の報酬シグナル密度を確保し、長さ崩壊を回避
- **汎化性**: 学習された長さバイアスはドメイン間で転移可能
- Qwen3シリーズ（0.6B-30B）で検証し、ロバスト性と汎化性を実証

## 技術的詳細
- Training prompts and rollouts の詳細分解
- Reward shaping戦略の体系的比較
- Optimization strategies の効果分析

## 注目ポイント
- 約0.2M GPU時間という大規模実験
- LLM効率的推論の包括的ガイドライン
- Qwen3全スケールでの検証
