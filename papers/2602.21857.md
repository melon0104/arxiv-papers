---
layout: paper
title: "Distill and Align Decomposition for Enhanced Claim Verification"
arxiv_id: "2602.21857"
date: 2026-02-27
categories: [cs.AI, cs.CL, cs.LG]
conference: EACL 2026 Findings
---

# Distill and Align Decomposition for Enhanced Claim Verification

## 基本情報
- **arXiv ID**: 2602.21857
- **タイトル**: Distill and Align Decomposition for Enhanced Claim Verification
- **カテゴリ**: cs.AI, cs.CL, cs.LG
- **採択**: **EACL 2026 Findings**

## 概要
複雑なクレーム検証には文を検証可能なサブクレームに分解する必要があるが、既存手法は分解品質と検証性能の整合に課題。本研究はGroup Relative Policy Optimization (GRPO)を用いた強化学習アプローチで分解品質と検証器整合を同時最適化。

## 主な貢献
1. **構造化逐次推論**: 段階的な推論プロセス
2. **教師蒸留によるSFT**: 高品質な教師事例でのファインチューニング
3. **多目的報酬**: フォーマット遵守、検証器整合、分解品質のバランス

## 実験結果（6評価設定）
- 8B分解器が下流検証性能で**71.75% macro-F1**を達成
- プロンプトベースアプローチを上回る: **+1.99, +6.24**
- 既存RL手法を上回る: **+5.84**
- 人間評価でサブクレームの高品質を確認

## 意義
小規模言語モデルでも検証精度と分解品質を同時最適化することでSOTAクレーム検証を達成可能。

## リンク
- [arXiv](https://arxiv.org/abs/2602.21857)
- [PDF](https://arxiv.org/pdf/2602.21857)
