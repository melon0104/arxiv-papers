---
layout: default
title: "Stable Adaptive Thinking via Advantage Shaping and Length-Aware Gradient Regulation"
---

# CPAS + LAGR: LRMの安定した適応的思考

[arXiv:2602.22556](https://arxiv.org/abs/2602.22556)

## 概要
Large Reasoning Models (LRMs)は拡張された推論トレースで高性能を達成するが、低複雑度クエリに対する「過剰思考」が問題。既存手法は不安定な精度-効率トレードオフと異種推論行動への脆弱性に苦しむ。

## 提案手法
2段階フレームワークで安定した適応的思考を実現：

### Stage 1: Hybrid Fine-Tuning
- thinking/no-thinkingの両行動にモデルを露出
- 良好な初期化を確立

### Stage 2: Adaptive RL
- **CPAS (Correctness-Preserving Advantage Shaping)**: 正しい長鎖推論の抑制を回避
- **LAGR (Length-Aware Gradient Regulation)**: 推論長の異種性下で最適化を安定化

## 実験結果
- Qwen2.5-1.5B: **+3.7精度ポイント**、トークン**40.6%削減**
- Qwen2.5-7B: **+3.6精度ポイント**、トークン**43.9%削減**
- 問題難易度変化・分布外タスクでもロバスト性を確認

## 技術的意義
- 推論長異種性への対応が鍵
- 正しい推論は長くても抑制しない設計
- 精度と効率の安定したトレードオフ

## 選定理由
- LRM効率化の実践的課題に取り組む
- 40%以上のトークン削減は実用的に重要
