# Can Post-Training Transform LLMs into Causal Reasoners?

**arXiv**: [2602.06337](https://arxiv.org/abs/2602.06337)  
**日付**: 2026-02-09  
**分野**: cs.CL（自然言語処理）  
**機関**: OpenCausaLab

## 概要

LLMの因果推論能力をポストトレーニングで強化できるかを体系的に検証。CauGymデータセット（7種類の因果タスク＋5種類のテストセット）を構築し、SFT/DPO/KTO/PPO/GRPOの5種類のポストトレーニング手法を評価。

## 技術的ポイント

- **CauGymデータセット**: 因果推論に特化した包括的なベンチマーク
- **ポストトレーニング比較**: SFT/DPO/KTO/PPO/GRPOを系統的に評価
- **小規模モデルの可能性**: 適切なポストトレーニングで大規模モデルを上回る

## 結果

- **CaLMベンチマーク**: 14Bモデルが**93.5%精度**を達成
  - OpenAI o3: 55.4%を大幅に上回る
- **汎化性能**: 分布シフト・ノイズデータに対して頑健
- **初の系統的エビデンス**: ポストトレーニングで信頼性の高い因果推論が可能

## コード

GitHub: https://github.com/OpenCausaLab/CauGym

## 選定理由

- **コード公開**: GitHub
- 因果推論という重要課題でo3を大幅に上回る結果
