# DRIFT: Decoupled Reasoning with Implicit Fact Tokens

## 基本情報
- **arXiv**: [2602.10021](https://arxiv.org/abs/2602.10021)
- **カテゴリ**: cs.CL, cs.AI
- **投稿日**: 2026-02-10
- **コード**: [GitHub](https://github.com/Lancelot-Xie/DRIFT)

## 一言まとめ
知識抽出と推論を分離するデュアルモデルアーキテクチャ。長文脈タスクで同サイズモデル中最高性能を達成。

## 概要
LLMへの広範な動的知識の統合は、事実データと推論パターンの絡み合いにより困難。RAGはコンテキスト長制限やretrieveノイズ、知識編集は破滅的忘却のリスクがある。

## 技術的貢献
- **デュアルモデルアーキテクチャ**: 知識抽出と推論を明示的に分離
- **軽量知識モデル**: クエリ条件付きで文書を暗黙的ファクトトークンに動的圧縮
- **埋め込み空間投影**: 密な表現を推論モデルの埋め込み空間に投影
- **静的プロンプト圧縮との差別化**: 動的圧縮で精度維持

## 実験結果
- 長文脈タスクで同等サイズモデル中最高性能
- 強力なベースラインを大幅に上回る
- 有効コンテキスト長と推論能力を拡張

## 選定理由
✅ コード公開 (GitHub)
✅ 実用的なRAG代替手法
