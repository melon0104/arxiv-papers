# Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning

## 概要
Visual Token Pruning（VTP）を訓練段階に適用し、MLLMの訓練効率を大幅改善。推論時だけでなく訓練時のビジュアルトークン削減を実現。

## 主要貢献
- **訓練時VTP**: 従来の推論時効率化を訓練に拡張
- モデルサイズ・パラメータ削減とは別軸の効率化
- Fast-Slow学習戦略

## 技術詳細
- ビジュアルトークン数削減による訓練高速化
- VTPの訓練段階適用時の課題を解決
- 精度を維持しつつ計算コスト削減

## 注目ポイント
⚡ MLLM訓練の新しい効率化軸

## リンク
- arXiv: https://arxiv.org/abs/2602.03815
