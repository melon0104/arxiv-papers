---
layout: paper
title: "データアノテーションにおける主観性と「Ground Truth」幻想の解剖"
---

# Dissecting Subjectivity and the "Ground Truth" Illusion in Data Annotation

## 基本情報
- **arXiv**: https://arxiv.org/abs/2602.11318
- **カテゴリ**: cs.AI, cs.CL, cs.CY
- **著者**: Sheza Munir et al.
- **投稿日**: 2026-02-11

## 選定理由
✅ **大規模サーベイ**: 2020-2025年の7トップ会場から346論文を分析
✅ **重要な問題提起**: AIの公平性と多様性に関する根本的課題

## 概要
機械学習における「ground truth」は訓練・評価に使用される正解ラベルを指すが、この基本的パラダイムは人間の不一致を技術的ノイズではなく重要な社会技術的シグナルとして扱う実証主義的誤謬に基づく。

## 研究手法
- **対象**: ACL, AIES, CHI, CSCW, EAAMO, FAccT, NeurIPS（2020-2025）
- **スクリーニング**: 30,897件から3,042件の高リコールコーパス、最終346論文

## 主要発見
- **位置的可読性の体系的失敗**: human-as-verifierモデルへの移行がアンカリングバイアスを導入
- **地理的覇権**: 西洋規範が普遍的ベンチマークとして強制
- **パフォーマティブ・アライメント**: 不安定なデータワーカーが経済的ペナルティ回避のため依頼者コンプライアンスを優先
- **「ノイジーセンサー」誤謬批判**: 文化的多元主義をランダムエラーと誤診

## 提案
- 不一致を文化的に適切なモデル構築に必須の高忠実度シグナルとして回復
- 多元的アノテーションインフラストラクチャへのロードマップ

## 所感
AI研究における根本的な前提を問い直す重要な批判的研究。多様性と公平性の観点から必読。
