---
layout: default
title: "LANCER: LLM Reranking for Nugget Coverage"
---

# LANCER: LLM Reranking for Nugget Coverage

arXiv:2601.22008
https://arxiv.org/abs/2601.22008

ECIR 2026 採択

---

## 概要

従来の検索は「関連度ランキング」に最適化されているが、レポート自動生成などのlong-form RAGでは「情報カバレッジ」が重要。LANCERはLLMベースのリランキング手法で、情報ナゲット（情報の断片）のカバレッジを最大化する。

## 背景・課題

**Short-form RAG vs Long-form RAG：**
- Short-form: 「東京タワーの高さは？」→ 1つの事実で回答可能
- Long-form: 「AIの歴史についてレポートを書いて」→ 多様な情報が必要

**従来手法の限界：**
- BM25やdense retrieverは「関連度」でランキング
- 上位文書が似た内容に偏りがち（冗長性）
- 情報の網羅性（カバレッジ）は考慮されない

## 提案手法

LANCERは3ステップで動作：

### Step 1: サブクエスチョン生成
- LLMを使って、元のクエリを満たすために必要なサブクエスチョンを生成
- 例：「AIの歴史」→「AIの起源は？」「第一次AIブームとは？」「深層学習の登場は？」など

### Step 2: 文書-サブクエスチョンマッピング
- 各候補文書がどのサブクエスチョンに回答するかをLLMで予測
- 文書ごとにカバーする「情報ナゲット」を特定

### Step 3: カバレッジ最大化リランキング
- できるだけ多くのサブクエスチョンをカバーするように文書を選択・順位付け
- 貪欲法またはサブモジュラ最適化

## 実験結果

- α-nDCG（多様性考慮の評価指標）で他のLLMリランカーを上回る
- 情報カバレッジ指標でも優位
- **Oracle分析：サブクエスチョン生成の品質が性能を大きく左右**

## 意義・応用

- レポート生成、調査支援、複雑なQAに有効
- RAGパイプラインのリランカーとして組み込み可能
- 「関連度」から「網羅性」へのパラダイムシフト

## 関連研究

- MMR（Maximal Marginal Relevance）: 古典的な多様性手法
- LLMリランカー（RankGPT等）
- Query2Doc、HyDE（クエリ拡張手法）
