# MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling

## 概要
エッジデバイス（スマートフォン等）でのLLMスケーリング手法。パラメータ数やテスト時計算量増加に頼らず、ストレージベースの知識注入で性能向上。

## 主要貢献
- **エッジ制約下でのスケーリング**: RAM/NPUリソース制限への対応
- ストレージを活用した専門知識注入
- プロキシモデル不要のメモリベースアプローチ

## 技術詳細
- 従来のパラメータスケーリング戦略の限界を回避
- ストレージベースの容量拡張
- エッジデバイス向け最適化

## 注目ポイント
📱 モバイル/エッジLLMの実用性向上

## リンク
- arXiv: https://arxiv.org/abs/2602.03359
