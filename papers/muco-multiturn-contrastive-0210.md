# MuCo: Multi-turn Contrastive Learning for Multimodal Embedding Model

**arXiv**: [2602.06393](https://arxiv.org/abs/2602.06393)  
**日付**: 2026-02-09  
**分野**: cs.IR（情報検索）  
**機関**: NAVER AI

## 概要

マルチモーダル埋め込みモデルにおける「シングルターン」対比学習の限界を克服する新手法。MLLMの会話的性質を活用し、単一画像に関連する複数のクエリ・ターゲットペアを1回のフォワードパスで処理。

## 技術的ポイント

- **Multi-Turn Contrastive Learning (MuCo)**: 対話形式でマルチターンのクエリ・ターゲットペアを処理
- **M3Tデータセット**: 500万件のマルチモーダル・マルチターンデータセットを新規構築
- **効率性**: 共有コンテキスト表現から複数の埋め込みを同時抽出
- **実効バッチサイズ増大**: 訓練効率の大幅改善

## 結果

- **MMEB/M-BEIRベンチマーク**: SOTAの検索性能を達成
- **表現の一貫性**: モダリティ間で改善
- **訓練効率**: 従来手法を大幅に上回る

## コード

GitHub: https://github.com/naver-ai/muco

## 選定理由

- **コード公開**: GitHubでオープンソース
- マルチモーダル埋め込みの新パラダイムを提示
