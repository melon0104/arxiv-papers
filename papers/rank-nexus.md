---
layout: default
title: "Rank-Nexus: Multimodal Reranking"
---

# Rank-Nexus: When Vision Meets Texts in Listwise Reranking

arXiv:2601.20623
https://arxiv.org/abs/2601.20623

---

## 概要

画像+テキストのマルチモーダル文書リランキングを、2Bパラメータの軽量モデルで実現。段階的クロスモーダル訓練により、7B-32Bの大規模モデルに匹敵する性能を達成。

## 背景・課題

**マルチモーダル検索の需要：**
- 商品検索（画像+説明文）
- 学術論文検索（図表+本文）
- ニュース検索（写真+記事）

**既存手法の問題：**
1. モダリティギャップ：画像とテキストの表現空間が異なる
2. アラインドデータ不足：画像-テキストペアのリランキングデータが少ない
3. 計算コスト：7B-32Bの大規模モデルが必要とされていた

## 提案手法

### Progressive Cross-Modal Training（段階的クロスモーダル訓練）

**Phase 1: テキストブランチの訓練**
- 豊富なテキストリランキングデータ（MS MARCO等）を活用
- 大規模リランカーからの知識蒸留

**Phase 2: 画像ブランチの訓練**
- 画像リランキングデータは少ない
- MLLMを使って画像検索ベンチマークの画像にキャプション生成
- キャプションベースで蒸留ペアを構築

**Phase 3: 統合訓練**
- 画像+テキスト統合リランキングデータを蒸留
- 両モダリティを同時に扱えるように調整

### Listwise Reranking
- ポイントワイズ（1文書ずつ）ではなくリストワイズ（複数文書同時）
- 文書間の相対的な関係を考慮

## 実験結果

**テキストベンチマーク：**
- TREC: 強いベースラインに匹敵
- BEIR: 汎化性能も高い

**画像ベンチマーク：**
- INQUIRE: 高精度
- MMDocIR: マルチモーダル文書検索でも有効

**モデルサイズ：2B**（競合は7B-32B）

## 意義・応用

- ECサイトの商品検索改善
- マルチモーダルRAG
- 軽量なのでエッジデプロイも視野

## 関連研究

- CLIP / BLIP（マルチモーダル基盤モデル）
- monoT5 / RankT5（テキストリランカー）
- LLaVA（MLLM）
