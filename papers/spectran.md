---
layout: default
title: "SpecTran: Spectral-Aware Adapter"
---

# SpecTran: Spectral-Aware Transformer-based Adapter for LLM-Enhanced Sequential Recommendation

arXiv:2601.21986
https://arxiv.org/abs/2601.21986

---

## 概要

逐次推薦モデルにLLMのセマンティック埋め込みを注入するアダプタ。スペクトル領域で動作し、従来手法の次元崩壊問題を解決。4データセット×3バックボーンで平均+9.17%改善。

## 背景・課題

**逐次推薦（Sequential Recommendation）とは：**
- ユーザーの行動履歴から次に興味を持つアイテムを予測
- 例：視聴履歴→次に見る動画、購入履歴→次に買う商品

**従来の逐次推薦モデル：**
- アイテムIDを低次元埋め込みに変換
- RNN / Transformer でシーケンスをモデル化
- 問題：テキスト情報（タイトル、説明文）を活用できていない

**LLM埋め込みの導入：**
- LLMでアイテムのテキストを高次元セマンティック埋め込みに
- これを逐次推薦モデルに注入したい

**既存の注入方法の問題：**

| 手法 | 問題 |
|------|------|
| Adapter方式 | 次元崩壊：情報が少数の次元に集中 |
| SVD方式 | 主成分のみ使用、残りの情報を捨てる |

## 提案手法

### スペクトル領域でのTransformer Adapter

1. **SVD分解**：LLM埋め込みを特異値分解
2. **全スペクトルへのAttention**：主成分だけでなく全成分を入力
3. **学習可能なスペクトル位置エンコーディング**：
   - 各特異値の大きさを位置情報として注入
   - Transformerが「どの成分が重要か」を学習

### なぜスペクトル領域？
- 次元崩壊を防ぐ：情報が特定次元に偏らない
- 情報損失を防ぐ：全スペクトルを活用
- 帰納バイアス：特異値という事前知識を活用

## 実験結果

**データセット：** 4種類（Amazon、Yelp等）
**バックボーン：** SASRec、BERT4Rec、GRU4Rec

**結果：**
- 全組み合わせでベースライン超え
- 平均 +9.17% 改善
- 次元崩壊の緩和を可視化で確認

## 意義・応用

- LLMの知識を推薦システムに効率的に転移
- 既存の逐次推薦モデルにプラグイン可能
- コールドスタート問題の緩和にも期待

## 関連研究

- SASRec / BERT4Rec（逐次推薦モデル）
- P5 / TALLRec（LLMベース推薦）
- LoRA / Adapter（効率的ファインチューニング）
